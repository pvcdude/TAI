# ğŸ“… Month 3 â€“ Linear Algebra & ML Foundations (November)

### **Weeks 8â€“9: Linear Algebra for ML**

**Core Topics**

- Vectors = features (OHLCV).
    
- Dot product = weighted sum of signals.
    
- Matrices = stacking multiple days/features.
    
- Eigenvalues/eigenvectors = variance directions.
    
- PCA (Principal Component Analysis).
    

**Practical Work**

- Represent 30 days of OHLCV as a matrix.
    
- Compute covariance + eigenvectors with NumPy.
    
- Apply PCA to reduce indicators â†’ plot in 2D.
    

**Deliverable:** PCA visualization notebook â†’ 10 features reduced to 2D scatterplot.

ğŸ‘‰ **Skill learned:** **dimensionality reduction** â†’ simplify noisy features.

---

### **Weeks 10â€“11: ML Algorithm Fundamentals**

**Core Topics**

- Linear regression â†’ predict price.
    
- Logistic regression â†’ classify up/down.
    
- Decision trees â†’ rules from data.
    
- Random forests + boosting â†’ ensemble learning.
    
- SVMs â†’ separating market states.
    
- Neural nets intro â†’ perceptron + activation.
    

**Practical Work**

- Fit regression models on synthetic trading data.
    
- Train a tree classifier to predict â€œgreen/red candle.â€
    
- Experiment with SVM on indicator dataset.
    

**Deliverable:** A classifier that predicts **next-day up/down** with accuracy report.

ğŸ‘‰ **Skill learned:** implement your **first predictive trading models**.